{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch len 1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "example_dir_path = '../proteinmpnn-input-examples'\n",
    "\n",
    "parsed_pdbs_path = f'{example_dir_path}/parsed_pdbs.jsonl'\n",
    "fixed_pdbs_path = f'{example_dir_path}/fixed_pdbs.jsonl'\n",
    "tied_pdbs_path = f'{example_dir_path}/tied_pdbs.jsonl'\n",
    "\n",
    "with open(parsed_pdbs_path) as fp:\n",
    "    parsed_pdbs = json.load(fp)\n",
    "\n",
    "with open(fixed_pdbs_path) as fp:\n",
    "    fixed_pdbs = json.load(fp)\n",
    "\n",
    "with open(tied_pdbs_path) as fp:\n",
    "    tied_pdbs = json.load(fp)\n",
    "\n",
    "\n",
    "batch = [parsed_pdbs]\n",
    "print('batch len', len(batch))\n",
    "tied_positions_dict = tied_pdbs\n",
    "ca_only = False\n",
    "# this would not be null if user provides args.chain_id_jsonl\n",
    "chain_dict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from russell_protein.protein_mpnn.input_types import (\n",
    "    ProteinMPNNInput,\n",
    ")\n",
    "\n",
    "from russell_protein.protein_mpnn.input_process import process_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Design: 0\n",
      "0 A\n",
      "1 B\n",
      "2 C\n",
      "3 D\n"
     ]
    }
   ],
   "source": [
    "protein_mpnn_input = ProteinMPNNInput(\n",
    "    tied_positions_details = tied_positions_dict,\n",
    ")\n",
    "\n",
    "r1 = process_run(\n",
    "    protein_mpnn_input,\n",
    "    [batch]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1.chain_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ProteinMPNN.protein_mpnn_utils import tied_featurize\n",
    "\n",
    "tfex = tied_featurize(batch, 'cpu', chain_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True) tensor(True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/95/40g56m011614lbl69wt_5llc0000gn/T/ipykernel_72324/1350733227.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tfex = torch.tensor(X_tfex, dtype=torch.float64)\n",
      "/var/folders/95/40g56m011614lbl69wt_5llc0000gn/T/ipykernel_72324/1350733227.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  S_tfex = torch.tensor(S_tfex, dtype=torch.float64)\n",
      "/var/folders/95/40g56m011614lbl69wt_5llc0000gn/T/ipykernel_72324/1350733227.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mask_tfex = torch.tensor(mask_tfex, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "X_tfex = tfex[0]\n",
    "X = torch.tensor(r1.X)\n",
    "mask = torch.tensor(r1.mask)\n",
    "\n",
    "S_tfex, mask_tfex = tfex[1], tfex[2]\n",
    "\n",
    "X_tfex = torch.tensor(X_tfex, dtype=torch.float64)\n",
    "S_tfex = torch.tensor(S_tfex, dtype=torch.float64)\n",
    "mask_tfex = torch.tensor(mask_tfex, dtype=torch.float64)\n",
    "\n",
    "# Element-wise comparison\n",
    "print(\n",
    "    torch.all(torch.isclose(X_tfex, X)),\n",
    "    #torch.all(torch.isclose(S_tfex, r1.S)),\n",
    "    torch.all(torch.isclose(mask_tfex, mask))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "#return\n",
    "#\n",
    "# X_out,\n",
    "# S,\n",
    "# mask,\n",
    "# lengths,\n",
    "# chain_M,\n",
    "# chain_encoding_all,\n",
    "# letter_list_list,\n",
    "# visible_list_list,\n",
    "# masked_list_list,\n",
    "# masked_chain_length_list_list,\n",
    "# chain_M_pos,\n",
    "# omit_AA_mask,\n",
    "# residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef_all, pssm_bias_all, pssm_log_odds_all, bias_by_res_all, tied_beta\n",
    "\n",
    "residue_idx = tfex[12]\n",
    "\n",
    "# Element-wise comparison\n",
    "print(\n",
    "    torch.all(torch.isclose(residue_idx, r1.residue_indexes))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FEATURIZATION LAYER\n",
    "\n",
    "#E, top_k_neighbor_indexes = self.features(X, mask, residue_idx, chain_encoding_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 300])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Tuple\n",
    "from russell_protein.protein_mpnn.input_process import ATOM_ORDER_MAP_FOUR_ATOMS\n",
    "\n",
    "CA_INDEX = ATOM_ORDER_MAP_FOUR_ATOMS['CA']\n",
    "N_INDEX = ATOM_ORDER_MAP_FOUR_ATOMS['N']\n",
    "C_INDEX = ATOM_ORDER_MAP_FOUR_ATOMS['C']\n",
    "O_INDEX = ATOM_ORDER_MAP_FOUR_ATOMS['O']\n",
    "\n",
    "def get_atom_positions(X):\n",
    "    \"\"\"Return the positions of the atoms in the input tensor X including virtual atom \"Cb\".\"\"\"\n",
    "\n",
    "    # b is distance between Ca and N\n",
    "    b = X[:,:,CA_INDEX,:] - X[:,:,N_INDEX,:]\n",
    "\n",
    "    # c is distance between C and Ca\n",
    "    c = X[:,:, C_INDEX,:] - X[:,:, CA_INDEX,:]\n",
    "    a = torch.cross(b, c, dim=-1)\n",
    "\n",
    "    Cb = -0.58273431*a + 0.56802827*b - 0.54067466*c + X[:,:,CA_INDEX,:]\n",
    "    Ca = X[:,:,CA_INDEX,:]\n",
    "    N = X[:,:,N_INDEX,:]\n",
    "    C = X[:,:,C_INDEX,:]\n",
    "    O = X[:,:,O_INDEX,:]\n",
    "\n",
    "    return Ca, Cb, N, C, O\n",
    "\n",
    "def compute_pairwise_distances(\n",
    "    atom_positions: torch.Tensor,\n",
    "    mask: torch.Tensor,\n",
    "    top_k : int,\n",
    "    eps: float = 1e-6\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Compute pairwise Euclidean distances between residues based on their Cα atom positions.\n",
    "\n",
    "    Args:\n",
    "        atom_positions (torch.Tensor): Tensor of shape (B, L, 3) representing the Cα atomic coordinates.\n",
    "        mask (torch.Tensor): Tensor of shape (B, L) indicating valid residues (1 for valid, 0 for padding).\n",
    "        top_k (int): Number of nearest neighbors to consider.\n",
    "        eps (float, optional): Small epsilon value to prevent division by zero in sqrt operation. Default is 1e-6.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, torch.Tensor]:\n",
    "            - Distance matrix of shape (B, L, K) containing the top-K nearest neighbor distances.\n",
    "            - Index matrix of shape (B, L, K) containing the indices of the nearest neighbors.\n",
    "    \"\"\"\n",
    "    # Create a 2D mask to exclude invalid residues\n",
    "    pairwise_mask = mask.unsqueeze(1) * mask.unsqueeze(2)  # Shape: (B, L, L)\n",
    "\n",
    "    # Compute pairwise distance matrix\n",
    "    displacement = atom_positions.unsqueeze(1) - atom_positions.unsqueeze(2)  # Shape: (B, L, L, 3)\n",
    "    distance_matrix = pairwise_mask * torch.sqrt(torch.sum(displacement ** 2, dim=-1) + eps)  # Shape: (B, L, L)\n",
    "\n",
    "    # Adjust distances for padded residues to ensure they are ignored\n",
    "    max_distance, _ = torch.max(distance_matrix, dim=-1, keepdim=True)\n",
    "    adjusted_distances = distance_matrix + (1.0 - pairwise_mask) * max_distance\n",
    "\n",
    "    # Select top-K nearest neighbors\n",
    "    k_neighbors = min(top_k, atom_positions.shape[1])\n",
    "    top_k_distances, neighbor_indices = torch.topk(adjusted_distances, k_neighbors, dim=-1, largest=False)\n",
    "\n",
    "    return top_k_distances, neighbor_indices\n",
    "\n",
    "def gather_edges(edges, neighbor_idx):\n",
    "    \"\"\"This function extracts edge features from a full adjacency matrix (edges)\n",
    "    based on neighbor indices (neighbor_idx).\n",
    "\n",
    "    edges [B,N,N,C] at\n",
    "    Neighbor indices [B,N,K] =>\n",
    "\n",
    "    Returns\n",
    "        Neighbor features [B,N,K,C]\n",
    "    \"\"\"\n",
    "\n",
    "    neighbors = neighbor_idx.unsqueeze(-1).expand(-1, -1, -1, edges.size(-1))\n",
    "    edge_features = torch.gather(edges, 2, neighbors)\n",
    "    return edge_features\n",
    "\n",
    "def get_rbf_for_distances(D, num_rbf):\n",
    "    \"\"\"This function takes D, a tensor of distances, and transforms them into a higher-dimensional RBF space.\"\"\"\n",
    "\n",
    "    # WHY 2-22?\n",
    "    # ChatGPT thinks \"2 Å to 22 Å (angstroms) is a reasonable range for interatomic or residue distances in proteins.\"\n",
    "    D_min, D_max, D_count = 2., 22., num_rbf\n",
    "    D_mu = torch.linspace(D_min, D_max, D_count, device=D.device) # Generate RBF centers\n",
    "\n",
    "    D_mu = D_mu.view([1,1,1,-1])  # Reshape for broadcasting\n",
    "    D_sigma = (D_max - D_min) / D_count  # Compute standard deviation\n",
    "    D_expand = torch.unsqueeze(D, -1)  # Expand D for broadcasting\n",
    "    RBF = torch.exp(-((D_expand - D_mu) / D_sigma)**2)  # Compute RBF transformation\n",
    "\n",
    "    return RBF\n",
    "\n",
    "def get_rbf(A, B, E_idx):\n",
    "    \"\"\"\"\"\"\n",
    "\n",
    "    # probably should make sure this is a good idea\n",
    "    num_rbf = E_idx.shape[-1]\n",
    "\n",
    "    D_A_B = torch.sqrt(torch.sum((A[:,:,None,:] - B[:,None,:,:])**2,-1) + 1e-6) #[B, L, L]\n",
    "    D_A_B_neighbors = gather_edges(D_A_B[:,:,:,None], E_idx)[:,:,:,0] #[B,L,K]\n",
    "    RBF_A_B = get_rbf_for_distances(D_A_B_neighbors, num_rbf)\n",
    "    return RBF_A_B\n",
    "\n",
    "\n",
    "def get_rbf_for_top_k_neighbors(\n",
    "    top_k_distances,\n",
    "    top_k_neighbor_indexes,\n",
    "    Ca, Cb, N, C, O,\n",
    "    num_rbfs\n",
    "):\n",
    "    rbfs = []\n",
    "    rbfs.append(get_rbf_for_distances(top_k_distances, num_rbfs))       #Ca-Ca\n",
    "    rbfs.append(get_rbf(N, N, top_k_neighbor_indexes))                  #N-N\n",
    "    rbfs.append(get_rbf(C, C, top_k_neighbor_indexes))                  #C-C\n",
    "    rbfs.append(get_rbf(O, O, top_k_neighbor_indexes))                  #O-O\n",
    "    rbfs.append(get_rbf(Cb, Cb, top_k_neighbor_indexes))                #Cb-Cb\n",
    "    rbfs.append(get_rbf(Ca, N, top_k_neighbor_indexes))                 #Ca-N\n",
    "    rbfs.append(get_rbf(Ca, C, top_k_neighbor_indexes))                 #Ca-C\n",
    "    rbfs.append(get_rbf(Ca, O, top_k_neighbor_indexes))                 #Ca-O\n",
    "    rbfs.append(get_rbf(Ca, Cb, top_k_neighbor_indexes))    #Ca-Cb\n",
    "    rbfs.append(get_rbf(N, C, top_k_neighbor_indexes))      #N-C\n",
    "    rbfs.append(get_rbf(N, O, top_k_neighbor_indexes))      #N-O\n",
    "    rbfs.append(get_rbf(N, Cb, top_k_neighbor_indexes))     #N-Cb\n",
    "    rbfs.append(get_rbf(Cb, C, top_k_neighbor_indexes))     #Cb-C\n",
    "    rbfs.append(get_rbf(Cb, O, top_k_neighbor_indexes))     #Cb-O\n",
    "    rbfs.append(get_rbf(O, C, top_k_neighbor_indexes))      #O-C\n",
    "    rbfs.append(get_rbf(N, Ca, top_k_neighbor_indexes))     #N-Ca\n",
    "    rbfs.append(get_rbf(C, Ca, top_k_neighbor_indexes))     #C-Ca\n",
    "    rbfs.append(get_rbf(O, Ca, top_k_neighbor_indexes))     #O-Ca\n",
    "    rbfs.append(get_rbf(Cb, Ca, top_k_neighbor_indexes))    #Cb-Ca\n",
    "    rbfs.append(get_rbf(C, N, top_k_neighbor_indexes))      #C-N\n",
    "    rbfs.append(get_rbf(O, N, top_k_neighbor_indexes))      #O-N\n",
    "    rbfs.append(get_rbf(Cb, N, top_k_neighbor_indexes))     #Cb-N\n",
    "    rbfs.append(get_rbf(C, Cb, top_k_neighbor_indexes))     #C-Cb\n",
    "    rbfs.append(get_rbf(O, Cb, top_k_neighbor_indexes))     #O-Cb\n",
    "    rbfs.append(get_rbf(C, O, top_k_neighbor_indexes))      #C-O\n",
    "    rbfs = torch.cat(tuple(rbfs), dim=-1)\n",
    "\n",
    "    return rbfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ca, Cb, N, C, O = get_atom_positions(X)\n",
    "\n",
    "top_k_distances, top_k_neighbor_indexes = compute_pairwise_distances(Ca, mask, 7)\n",
    "top_k_distances, top_k_neighbor_indexes\n",
    "\n",
    "rbfs = get_rbf_for_top_k_neighbors(\n",
    "    top_k_distances,\n",
    "    top_k_neighbor_indexes,\n",
    "    Ca, Cb, N, C, O,\n",
    "    16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 300, 7, 184])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 300, 3]),\n",
       " torch.Size([1, 300]),\n",
       " torch.Size([1, 300, 7]),\n",
       " torch.Size([1, 300, 7]),\n",
       " torch.Size([1, 300, 7]),\n",
       " torch.Size([1, 300, 7]))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ca.shape, mask.shape, n.shape, i.shape, top_k_distances.shape, top_k_neighbor_indexes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True), tensor(True))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(torch.isclose(n, top_k_distances)), torch.all(torch.isclose(i, top_k_neighbor_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/95/40g56m011614lbl69wt_5llc0000gn/T/ipykernel_72324/791218066.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(r1.chain_encodings)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 300, 300, 1]), torch.Size([1, 300, 7]))"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(r1.chain_encodings)\n",
    "\n",
    "y = ((x[:,:, None] - x[:,None,:]) == 0).long()\n",
    "y[:,:,:,None].shape, top_k_neighbor_indexes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[237], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m d_chains \u001b[38;5;241m=\u001b[39m ((r1\u001b[38;5;241m.\u001b[39mchain_encodings[:,:,\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m-\u001b[39m r1\u001b[38;5;241m.\u001b[39mchain_encodings[:,\u001b[38;5;28;01mNone\u001b[39;00m,:]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m      2\u001b[0m E_chains \u001b[38;5;241m=\u001b[39m gather_edges(d_chains[:,:,:,\u001b[38;5;28;01mNone\u001b[39;00m], top_k_neighbor_indexes)[:,:,:,\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m E_positional \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241m.\u001b[39membeddings(offset\u001b[38;5;241m.\u001b[39mlong(), E_chains)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03mE = torch.cat((E_positional, RBF_all), -1)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03mE = self.edge_embedding(E)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03mE = self.norm_edges(E)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "d_chains = ((r1.chain_encodings[:,:,None] - r1.chain_encodings[:,None,:]) == 0).long()\n",
    "E_chains = gather_edges(d_chains[:,:,:,None], top_k_neighbor_indexes)[:,:,:,0]\n",
    "E_positional = self.embeddings(offset.long(), E_chains)\n",
    "\n",
    "\"\"\"\n",
    "E = torch.cat((E_positional, RBF_all), -1)\n",
    "E = self.edge_embedding(E)\n",
    "E = self.norm_edges(E)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chain_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[200], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m offset \u001b[38;5;241m=\u001b[39m residue_indexes[:,:,\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m-\u001b[39m residue_indexes[:,\u001b[38;5;28;01mNone\u001b[39;00m,:]\n\u001b[1;32m      4\u001b[0m offset\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m----> 6\u001b[0m d_chains \u001b[38;5;241m=\u001b[39m ((\u001b[43mchain_labels\u001b[49m[:, :, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m-\u001b[39m chain_labels[:,\u001b[38;5;28;01mNone\u001b[39;00m,:])\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mlong() \u001b[38;5;66;03m#find self vs non-self interaction\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chain_labels' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 300, 7, 16])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PositionalEncodings(nn.Module):\n",
    "    \"\"\"This class takes in a tensor of offsets and outputs a tensor of positional encodings.\"\"\"\n",
    "\n",
    "    def __init__(self, num_embeddings, max_relative_feature=32):\n",
    "        super().__init__()\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.max_relative_feature = max_relative_feature\n",
    "        self.linear = nn.Linear(2*max_relative_feature+1+1, num_embeddings)\n",
    "\n",
    "    def forward(self, offset, mask):\n",
    "        d = torch.clip(offset + self.max_relative_feature, 0, 2*self.max_relative_feature)*mask + (1-mask)*(2*self.max_relative_feature+1)\n",
    "        d_onehot = torch.nn.functional.one_hot(d, 2*self.max_relative_feature+1+1)\n",
    "        E = self.linear(d_onehot.float())\n",
    "        return E\n",
    "\n",
    "\n",
    "class ProteinEncoding(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_edge_features,\n",
    "        num_rbfs=16,\n",
    "        top_k=30,\n",
    "        num_positional_embeddings=16,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_rbfs = num_rbfs\n",
    "        self.num_positional_embeddings = num_positional_embeddings\n",
    "\n",
    "        num_node_in = 6\n",
    "        num_edge_in = num_positional_embeddings + num_rbfs * 25 # what's 25?\n",
    "\n",
    "        self.positional_embedding = PositionalEncodings(\n",
    "            num_embeddings = self.num_positional_embeddings,\n",
    "            max_relative_feature = 32\n",
    "        )\n",
    "\n",
    "        self.edge_embedding = nn.Linear(num_edge_in, num_edge_features, bias=False)\n",
    "        self.norm_edges = nn.LayerNorm(num_edge_features)\n",
    "\n",
    "\n",
    "    def build_rbf_features(self, X, top_k_distances, top_k_neighbor_indexes):\n",
    "        Ca, Cb, N, C, O = get_atom_positions(X)\n",
    "\n",
    "        rbfs = get_rbf_for_top_k_neighbors(\n",
    "            top_k_distances,\n",
    "            top_k_neighbor_indexes,\n",
    "            Ca, Cb, N, C, O,\n",
    "            self.num_rbfs\n",
    "        )\n",
    "\n",
    "        return rbfs\n",
    "\n",
    "    def build_positional_encoding_input(self, X, mask, residue_indexes, chain_encodings):\n",
    "        # so (B, L_max) and the None's add another dimension\n",
    "        # then we broadcast subtract so we end up with (B, L_max, L_max)\n",
    "        offset = residue_indexes[:,:,None] - residue_indexes[:,None,:]\n",
    "\n",
    "        # we add another dimension so offset becomes (B, L_max, L_max, 1)\n",
    "        offset = gather_edges(offset[:,:,:,None], top_k_neighbor_indexes)[:,:,:,0] #[B, L, K]\n",
    "\n",
    "        d_chains = ((chain_encodings[:,:,None] - chain_encodings[:,None,:]) == 0).long()\n",
    "        E_chains = gather_edges(d_chains[:,:,:,None], top_k_neighbor_indexes)[:,:,:,0]\n",
    "\n",
    "        return offset.long(), E_chains\n",
    "\n",
    "    def forward(self, X, mask, residue_indexes, chain_encodings):\n",
    "        Ca = X[:,:,CA_INDEX,:]\n",
    "        top_k_distances, top_k_neighbor_indexes = compute_pairwise_distances(Ca, mask, self.top_k)\n",
    "\n",
    "        rbfs = self.build_rbf_features(X, top_k_distances, top_k_neighbor_indexes)\n",
    "\n",
    "        offset, E_chains = self.build_positional_encoding_input(X, mask, residue_indexes, chain_encodings)\n",
    "\n",
    "        # Pass the offset and chain encodings to the positional embedding layer\n",
    "        E_positional = self.positional_embedding(offset, E_chains)\n",
    "        E = torch.cat((E_positional, rbfs), -1)\n",
    "        E = self.edge_embedding(E)\n",
    "        E = self.norm_edges(E)\n",
    "        return E, top_k_neighbor_indexes\n",
    "\n",
    "\n",
    "\n",
    "forward(None, X, mask, residue_idx, r1.chain_encodings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(offset).long().dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        E_chains = gather_edges(d_chains[:,:,:,None], E_idx)[:,:,:,0]\n",
    "        E_positional = self.embeddings(offset.long(), E_chains)\n",
    "        E = torch.cat((E_positional, RBF_all), -1)\n",
    "        E = self.edge_embedding(E)\n",
    "        E = self.norm_edges(E)\n",
    "        return E, E_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3455611911.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[118], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"\"\" Extract protein features \"\"\"\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "class ProteinFeatures(nn.Module):\n",
    "    def __init__(self, edge_features, node_features, num_positional_embeddings=16,\n",
    "        num_rbf=16, top_k=30, augment_eps=0., num_chain_embeddings=16):\n",
    "        \"\"\" Extract protein features \"\"\"\n",
    "        super(ProteinFeatures, self).__init__()\n",
    "        self.edge_features = edge_features\n",
    "        self.node_features = node_features\n",
    "        self.top_k = top_k\n",
    "        self.augment_eps = augment_eps\n",
    "        self.num_rbf = num_rbf\n",
    "        self.num_positional_embeddings = num_positional_embeddings\n",
    "\n",
    "        self.embeddings = PositionalEncodings(num_positional_embeddings)\n",
    "        node_in, edge_in = 6, num_positional_embeddings + num_rbf*25\n",
    "        self.edge_embedding = nn.Linear(edge_in, edge_features, bias=False)\n",
    "        self.norm_edges = nn.LayerNorm(edge_features)\n",
    "\n",
    "    def _dist(self, X, mask, eps=1E-6):\n",
    "        mask_2D = torch.unsqueeze(mask,1) * torch.unsqueeze(mask,2)\n",
    "        dX = torch.unsqueeze(X,1) - torch.unsqueeze(X,2)\n",
    "        D = mask_2D * torch.sqrt(torch.sum(dX**2, 3) + eps)\n",
    "        D_max, _ = torch.max(D, -1, keepdim=True)\n",
    "        D_adjust = D + (1. - mask_2D) * D_max\n",
    "        sampled_top_k = self.top_k\n",
    "        D_neighbors, E_idx = torch.topk(D_adjust, np.minimum(self.top_k, X.shape[1]), dim=-1, largest=False)\n",
    "        return D_neighbors, E_idx\n",
    "\n",
    "    def _rbf(self, D):\n",
    "        device = D.device\n",
    "        D_min, D_max, D_count = 2., 22., self.num_rbf\n",
    "        D_mu = torch.linspace(D_min, D_max, D_count, device=device)\n",
    "        D_mu = D_mu.view([1,1,1,-1])\n",
    "        D_sigma = (D_max - D_min) / D_count\n",
    "        D_expand = torch.unsqueeze(D, -1)\n",
    "        RBF = torch.exp(-((D_expand - D_mu) / D_sigma)**2)\n",
    "        return RBF\n",
    "\n",
    "\n",
    "    def _get_rbf(self, A, B, E_idx):\n",
    "        D_A_B = torch.sqrt(torch.sum((A[:,:,None,:] - B[:,None,:,:])**2,-1) + 1e-6) #[B, L, L]\n",
    "        D_A_B_neighbors = gather_edges(D_A_B[:,:,:,None], E_idx)[:,:,:,0] #[B,L,K]\n",
    "        RBF_A_B = self._rbf(D_A_B_neighbors)\n",
    "        return RBF_A_B\n",
    "\n",
    "    def forward(self, X, mask, residue_idx, chain_labels):\n",
    "        if self.augment_eps > 0:\n",
    "            X = X + self.augment_eps * torch.randn_like(X)\n",
    "\n",
    "        b = X[:,:,1,:] - X[:,:,0,:]\n",
    "        c = X[:,:,2,:] - X[:,:,1,:]\n",
    "        a = torch.cross(b, c, dim=-1)\n",
    "        Cb = -0.58273431*a + 0.56802827*b - 0.54067466*c + X[:,:,1,:]\n",
    "        Ca = X[:,:,1,:]\n",
    "        N = X[:,:,0,:]\n",
    "        C = X[:,:,2,:]\n",
    "        O = X[:,:,3,:]\n",
    "\n",
    "        D_neighbors, E_idx = self._dist(Ca, mask)\n",
    "\n",
    "        RBF_all = []\n",
    "        RBF_all.append(self._rbf(D_neighbors)) #Ca-Ca\n",
    "        RBF_all.append(self._get_rbf(N, N, E_idx)) #N-N\n",
    "        RBF_all.append(self._get_rbf(C, C, E_idx)) #C-C\n",
    "        RBF_all.append(self._get_rbf(O, O, E_idx)) #O-O\n",
    "        RBF_all.append(self._get_rbf(Cb, Cb, E_idx)) #Cb-Cb\n",
    "        RBF_all.append(self._get_rbf(Ca, N, E_idx)) #Ca-N\n",
    "        RBF_all.append(self._get_rbf(Ca, C, E_idx)) #Ca-C\n",
    "        RBF_all.append(self._get_rbf(Ca, O, E_idx)) #Ca-O\n",
    "        RBF_all.append(self._get_rbf(Ca, Cb, E_idx)) #Ca-Cb\n",
    "        RBF_all.append(self._get_rbf(N, C, E_idx)) #N-C\n",
    "        RBF_all.append(self._get_rbf(N, O, E_idx)) #N-O\n",
    "        RBF_all.append(self._get_rbf(N, Cb, E_idx)) #N-Cb\n",
    "        RBF_all.append(self._get_rbf(Cb, C, E_idx)) #Cb-C\n",
    "        RBF_all.append(self._get_rbf(Cb, O, E_idx)) #Cb-O\n",
    "        RBF_all.append(self._get_rbf(O, C, E_idx)) #O-C\n",
    "        RBF_all.append(self._get_rbf(N, Ca, E_idx)) #N-Ca\n",
    "        RBF_all.append(self._get_rbf(C, Ca, E_idx)) #C-Ca\n",
    "        RBF_all.append(self._get_rbf(O, Ca, E_idx)) #O-Ca\n",
    "        RBF_all.append(self._get_rbf(Cb, Ca, E_idx)) #Cb-Ca\n",
    "        RBF_all.append(self._get_rbf(C, N, E_idx)) #C-N\n",
    "        RBF_all.append(self._get_rbf(O, N, E_idx)) #O-N\n",
    "        RBF_all.append(self._get_rbf(Cb, N, E_idx)) #Cb-N\n",
    "        RBF_all.append(self._get_rbf(C, Cb, E_idx)) #C-Cb\n",
    "        RBF_all.append(self._get_rbf(O, Cb, E_idx)) #O-Cb\n",
    "        RBF_all.append(self._get_rbf(C, O, E_idx)) #C-O\n",
    "        RBF_all = torch.cat(tuple(RBF_all), dim=-1)\n",
    "\n",
    "        offset = residue_idx[:,:,None]-residue_idx[:,None,:]\n",
    "        offset = gather_edges(offset[:,:,:,None], E_idx)[:,:,:,0] #[B, L, K]\n",
    "\n",
    "        d_chains = ((chain_labels[:, :, None] - chain_labels[:,None,:])==0).long() #find self vs non-self interaction\n",
    "        E_chains = gather_edges(d_chains[:,:,:,None], E_idx)[:,:,:,0]\n",
    "        E_positional = self.embeddings(offset.long(), E_chains)\n",
    "        E = torch.cat((E_positional, RBF_all), -1)\n",
    "        E = self.edge_embedding(E)\n",
    "        E = self.norm_edges(E)\n",
    "        return E, E_idx\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAYBE WE WILL NEED SOME DAATA!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reimplement this shit\n",
    "    def _dist(self, X, mask, eps=1E-6):\n",
    "        mask_2D = torch.unsqueeze(mask,1) * torch.unsqueeze(mask,2)\n",
    "        dX = torch.unsqueeze(X,1) - torch.unsqueeze(X,2)\n",
    "        D = mask_2D * torch.sqrt(torch.sum(dX**2, 3) + eps)\n",
    "        D_max, _ = torch.max(D, -1, keepdim=True)\n",
    "        D_adjust = D + (1. - mask_2D) * D_max\n",
    "        sampled_top_k = self.top_k\n",
    "        D_neighbors, E_idx = torch.topk(D_adjust, np.minimum(self.top_k, X.shape[1]), dim=-1, largest=False)\n",
    "        return D_neighbors, E_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Optional\n",
    "\n",
    "class ProteinMPNNProteinFeatures(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_edge_features : int,\n",
    "        num_node_features : int,\n",
    "        num_positional_embeddings : Optional[int] = 16,\n",
    "        num_rbf : Optional[int] = 16,\n",
    "        top_k : Optional[int] = 30,\n",
    "        augment_eps : Optional[float] = 0.\n",
    "    ):\n",
    "        \"\"\" Extract protein features \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_edge_features = num_edge_features\n",
    "        self.num_node_features = num_node_features\n",
    "        self.num_rbf = num_rbf\n",
    "        self.num_positional_embeddings = num_positional_embeddings\n",
    "\n",
    "        self.top_k = top_k\n",
    "        self.augment_eps = augment_eps\n",
    "\n",
    "        self.embeddings = PositionalEncodings(num_positional_embeddings)\n",
    "        node_in, edge_in = 6, num_positional_embeddings + num_rbf*25\n",
    "        self.edge_embedding = nn.Linear(edge_in, edge_features, bias=False)\n",
    "        self.norm_edges = nn.LayerNorm(edge_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Tuple\n",
    "\n",
    "def compute_pairwise_distances(\n",
    "    self,\n",
    "    atom_positions: torch.Tensor,\n",
    "    mask: torch.Tensor,\n",
    "    eps: float = 1e-6\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Compute pairwise Euclidean distances between residues based on their Cα atom positions.\n",
    "\n",
    "    Args:\n",
    "        atom_positions (torch.Tensor): Tensor of shape (B, L, 3) representing the Cα atomic coordinates.\n",
    "        mask (torch.Tensor): Tensor of shape (B, L) indicating valid residues (1 for valid, 0 for padding).\n",
    "        eps (float, optional): Small epsilon value to prevent division by zero in sqrt operation. Default is 1e-6.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, torch.Tensor]:\n",
    "            - Distance matrix of shape (B, L, K) containing the top-K nearest neighbor distances.\n",
    "            - Index matrix of shape (B, L, K) containing the indices of the nearest neighbors.\n",
    "    \"\"\"\n",
    "    # Create a 2D mask to exclude invalid residues\n",
    "    pairwise_mask = mask.unsqueeze(1) * mask.unsqueeze(2)  # Shape: (B, L, L)\n",
    "\n",
    "    # Compute pairwise distance matrix\n",
    "    displacement = atom_positions.unsqueeze(1) - atom_positions.unsqueeze(2)  # Shape: (B, L, L, 3)\n",
    "    distance_matrix = pairwise_mask * torch.sqrt(torch.sum(displacement ** 2, dim=-1) + eps)  # Shape: (B, L, L)\n",
    "\n",
    "    # Adjust distances for padded residues to ensure they are ignored\n",
    "    max_distance, _ = torch.max(distance_matrix, dim=-1, keepdim=True)\n",
    "    adjusted_distances = distance_matrix + (1.0 - pairwise_mask) * max_distance\n",
    "\n",
    "    # Select top-K nearest neighbors\n",
    "    k_neighbors = min(self.top_k, atom_positions.shape[1])\n",
    "    top_k_distances, neighbor_indices = torch.topk(adjusted_distances, k_neighbors, dim=-1, largest=False)\n",
    "\n",
    "    return top_k_distances, neighbor_indices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
